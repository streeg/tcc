The experiment presented on this article earlier showed that when trying to contact the developers behind the code some of them replied to us showing that the piece of code with some kind of missuse or vulnerability presented by either cognicrypt or cryptoguard were in fact not their fault and in fact stemmed from external libraries used throughout the code. 

Having this concern in mind we have decided to tackle this problem. First we studied what we could do to identify if the application being analyzed were in fact using a external library with some kind of vulnerability. For that, we have found the article 'Automated Third-Party Library Detection for Android Applications: Are We There Yet?' written by Zhang in which briefly describes 5 of the most used programs to identify if exists code that were imported, them being: LibID, LibRadar, LibScout, LibPecker and ORLIS. Each of them attack the problem in different ways but all of them were rated within four criterias. Effectivness, efficiency/scalability, obfuscation resilience, ease of use. Before I describe them, like Zhang did, I'll be using tpl for third-party library. The first one, effectivness evaluates if the tools above can in fact explicit if the application on trial have or don't have tpls. In fact, in this study, were noted that the most effective one, LibScout, could only identify 49% of the tpls in a given application with 97% of precision, the second in line were LibId with 45% with only 85% precision, followed by libRadar with 40% with almost 98% of precision. LibPecker in fourth and ORLIS being the worst in this category. In all of them we must not ignore the fact that there were false positives. -Mainly caused for two reasons, tpls being dependent of others tpls and closed version of codes being very simillar bitwise which may cause problems for libScout and libRadar which uses hierarchy as a suplementary feature to indentify tpls.-(Deixo isso aqui?) The second criteria, efficiency/scalability, determines whether the solution is viable in large scale or not. Later after reviewing the five tools, this one was one of the main reasons for us choosing libScout as the tool used to scout for tpls. LibRadar, the first one on this category, could run with ease each application in 5 seconds or so. LibScout took 80 seconds in average. ORLIS in third took 23 minutes. LibId and LibPecker took 4 hours on average and LibId couldn't handle an application with a lot of external libraries as there were memory leak and the run just crashed. As this research would use several apps in different categories we choose to use the first two for the experiment, LibRadar and LibScout. The third criteria, obfuscation-resilient capability attacks the obfuscation problem in two different ways as there are lot of ways to obfuscate something. LibPecker won with ease this category exceding all the other four. As said earlier, due to the time it took to evaluate one app, we decided to use libScout, but this doesn't mean that libScout is bad at finding tpls on obfuscated code, just not the greatest. Finally the last criteria, ease of use. This category was not considered so deeply, since we scientists must have the ability to not only analyze a new tool but also learn to use it if necessary for some research. Anyway, libScout and libRadar outpeformed the others competitors.

The second step, use the selected tools to find if in a given application we could identify third party libraries. We started with ten selected apps using both libRadar and libScout. LibRadar and libScout results for the pilot were not similar. LibScout identified lot more tpls than libRadar due to the first one deeply analysing the application where the last one uses an clustering method to categorize if it is or not a tpl. To run the libRadar we had to set up a Redis server and loading a sample so libRadar can compare if the application on trial uses or not external libraries and the last time the sample were updated with a good cluster example was in 2017. Most of the apps analyzed were from 2017 and beyond. For that reason, libScout became the focus. 

In the third step, we have runned cognicrypt and cryptoguard on the same samples {...}
On the fourth we compared both libScout and cognicrypt/cryptoguard results {...} Escrever como um s√≥ step?
Finally the results are {...}
